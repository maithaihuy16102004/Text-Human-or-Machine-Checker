import streamlit as st
import tensorflow as tf
import pickle
import numpy as np
from tensorflow.keras.preprocessing.sequence import pad_sequences

# Thi·∫øt l·∫≠p giao di·ªán
st.set_page_config(page_title="Ki·ªÉm Tra VƒÉn B·∫£n", page_icon="üìù", layout="centered")
st.markdown("""
    <style>
    .main {background-color: #f0f2f6;}
    .stButton>button {background-color: #4CAF50; color: white; border-radius: 8px;}
    .stTextArea textarea {border-radius: 8px; border: 1px solid #ccc;}
    .result-box {padding: 10px; border-radius: 8px; font-size: 18px;}
    .success {background-color: #e6f4e6; border: 1px solid #4CAF50;}
    .error {background-color: #f4e6e6; border: 1px solid #ff3333;}
    </style>
""", unsafe_allow_html=True)

st.title("üìù Ki·ªÉm Tra VƒÉn B·∫£n: Con Ng∆∞·ªùi hay AI?")
st.markdown("Nh·∫≠p vƒÉn b·∫£n ƒë·ªÉ ki·ªÉm tra xem n√≥ ƒë∆∞·ª£c vi·∫øt b·ªüi con ng∆∞·ªùi hay t·∫°o b·ªüi AI.")

@st.cache_resource
def load_model():
    try:
        model = tf.keras.models.load_model(
            "transformer_model.keras",
            custom_objects={
                'positional_encoding': tf.keras.layers.Lambda(lambda x: x),
                'transformer_block': tf.keras.layers.Layer
            },
            compile=False,
            safe_mode=False
        )
        return model
    except Exception as e:
        st.error(f"L·ªói t·∫£i m√¥ h√¨nh: {e}")
        return None

@st.cache_resource
def load_tokenizer():
    try:
        with open("tokenizer.pkl", "rb") as f:
            return pickle.load(f)
    except Exception as e:
        st.error(f"L·ªói t·∫£i tokenizer: {e}")
        return None

model = load_model()
tokenizer = load_tokenizer()

if not model or not tokenizer:
    st.stop()

# Nh·∫≠p vƒÉn b·∫£n
user_input = st.text_area("Nh·∫≠p vƒÉn b·∫£n c·∫ßn ki·ªÉm tra", height=200, placeholder="D√°n ho·∫∑c nh·∫≠p vƒÉn b·∫£n t·∫°i ƒë√¢y...")

if st.button("üîç Ki·ªÉm Tra"):
    if user_input.strip():
        max_len = 512
        sequences = tokenizer.texts_to_sequences([user_input])
        padded = pad_sequences(sequences, maxlen=max_len, padding='post', truncating='post')
        
        with st.spinner("ƒêang ph√¢n t√≠ch..."):
            prediction = model.predict(padded, verbose=0)
            result = "Do AI t·∫°o" if prediction[0][0] > 0.5 else "Do con ng∆∞·ªùi vi·∫øt"
            st.markdown(f"""
                <div class='result-box success'>
                    <strong>K·∫øt qu·∫£:</strong> {result}
                </div>
            """, unsafe_allow_html=True)
    else:
        st.markdown("""
            <div class='result-box error'>
                Vui l√≤ng nh·∫≠p vƒÉn b·∫£n ƒë·ªÉ ki·ªÉm tra!
            </div>
        """, unsafe_allow_html=True)