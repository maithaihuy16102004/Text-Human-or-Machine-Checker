Ráº¥t tá»‘t. TÃ´i sáº½ viáº¿t láº¡i toÃ n bá»™ pháº§n mÃ´ táº£ dá»± Ã¡n cá»§a báº¡n thÃ nh báº£n `README.md` chuáº©n, Ä‘áº§y Ä‘á»§, bá»‘ cá»¥c rÃµ rÃ ng, vÄƒn phong chuyÃªn nghiá»‡p phÃ¹ há»£p cho kho mÃ£ nguá»“n trÃªn GitHub:

---

# AI vs Human Text Classification - Transformer Encoder

## ğŸ” Giá»›i Thiá»‡u Dá»± Ãn

Dá»± Ã¡n triá»ƒn khai má»™t mÃ´ hÃ¬nh **Transformer Encoder** tá»« Ä‘áº§u Ä‘á»ƒ phÃ¢n loáº¡i vÄƒn báº£n, xÃ¡c Ä‘á»‹nh xem ná»™i dung Ä‘Æ°á»£c viáº¿t bá»Ÿi **con ngÆ°á»i** hay táº¡o ra bá»Ÿi **AI**, dá»±a trÃªn bá»™ dá»¯ liá»‡u lá»›n tá»« Kaggle: [AI vs Human Text](https://www.kaggle.com/datasets/shanegerami/ai-vs-human-text).
Sau quÃ¡ trÃ¬nh huáº¥n luyá»‡n trÃªn Google Colab sá»­ dá»¥ng GPU T4, mÃ´ hÃ¬nh Ä‘áº¡t hiá»‡u suáº¥t ráº¥t cao vá»›i:

* **Accuracy**: 0.9992
* **F1-Score**: 0.9990

NgoÃ i ra, dá»± Ã¡n cÃ²n xÃ¢y dá»±ng má»™t á»©ng dá»¥ng web demo sá»­ dá»¥ng **Streamlit** giÃºp kiá»ƒm tra vÄƒn báº£n theo thá»i gian thá»±c.

---

## ğŸš€ TÃ­nh NÄƒng

* Huáº¥n luyá»‡n mÃ´ hÃ¬nh **Transformer Encoder** vá»›i cÃ¡c tham sá»‘ tá»‘i Æ°u:

  * `embed_dim=64`, `num_blocks=2`, `dropout_rate=0.3`.
* PhÃ¢n tÃ­ch vÃ  trá»±c quan hÃ³a quÃ¡ trÃ¬nh huáº¥n luyá»‡n (loss, precision).
* ÄÃ¡nh giÃ¡ hiá»‡u suáº¥t mÃ´ hÃ¬nh vá»›i cÃ¡c chá»‰ sá»‘:

  * Accuracy, Precision, Recall, F1-Score, Confusion Matrix.
* á»¨ng dá»¥ng web Streamlit kiá»ƒm tra vÄƒn báº£n trá»±c tuyáº¿n theo thá»i gian thá»±c.

---

## ğŸ–¥ï¸ YÃªu Cáº§u Há»‡ Thá»‘ng

* Python >= 3.8
* CÃ¡c thÆ° viá»‡n cáº§n thiáº¿t:

  * `tensorflow==2.15.0`
  * `numpy`
  * `pandas`
  * `scikit-learn`
  * `matplotlib`
  * `seaborn`
  * `streamlit`
  * `pickle`

---

## âš™ï¸ CÃ i Äáº·t

### 1ï¸âƒ£ Clone kho mÃ£ nguá»“n:

```bash
git clone https://github.com/<your-username>/<repository-name>.git
cd <repository-name>
```

### 2ï¸âƒ£ Thiáº¿t láº­p mÃ´i trÆ°á»ng:

**Táº¡o mÃ´i trÆ°á»ng áº£o (khuyáº¿n khÃ­ch):**

```bash
python -m venv venv
source venv/bin/activate  # TrÃªn Windows: venv\Scripts\activate
```

**CÃ i Ä‘áº·t cÃ¡c thÆ° viá»‡n:**

```bash
pip install -r requirements.txt
```

### 3ï¸âƒ£ Chuáº©n bá»‹ dá»¯ liá»‡u vÃ  mÃ´ hÃ¬nh:

* Táº£i file `transformer_model.keras` vÃ  `tokenizer.pkl` tá»« Google Drive (Ä‘Ã£ lÆ°u táº¡i `/content/drive/MyDrive/` trong quÃ¡ trÃ¬nh huáº¥n luyá»‡n), sau Ä‘Ã³ Ä‘áº·t vÃ o thÆ° má»¥c dá»± Ã¡n.
* Äáº£m báº£o bá»™ dá»¯ liá»‡u tá»« Kaggle Ä‘Ã£ Ä‘Æ°á»£c chuáº©n bá»‹ theo cáº¥u trÃºc tÆ°Æ¡ng á»©ng trong mÃ£ nguá»“n (pháº§n `train.py`).

---

## ğŸ“‚ Cáº¥u TrÃºc MÃ£ Nguá»“n

```bash
.
â”œâ”€â”€ train.py            # Huáº¥n luyá»‡n mÃ´ hÃ¬nh Transformer Encoder
â”œâ”€â”€ visualize.py        # Trá»±c quan hÃ³a quÃ¡ trÃ¬nh huáº¥n luyá»‡n
â”œâ”€â”€ evaluate.py         # ÄÃ¡nh giÃ¡ hiá»‡u suáº¥t mÃ´ hÃ¬nh
â”œâ”€â”€ app.py              # á»¨ng dá»¥ng web Streamlit kiá»ƒm tra vÄƒn báº£n
â”œâ”€â”€ requirements.txt    # Danh sÃ¡ch cÃ¡c thÆ° viá»‡n cáº§n cÃ i Ä‘áº·t
â”œâ”€â”€ transformer_model.keras  # MÃ´ hÃ¬nh Ä‘Ã£ huáº¥n luyá»‡n (cáº§n tá»± thÃªm)
â””â”€â”€ tokenizer.pkl       # Tokenizer Ä‘Ã£ lÆ°u (cáº§n tá»± thÃªm)
```

---

## ğŸ”¨ HÆ°á»›ng Dáº«n Sá»­ Dá»¥ng

### Huáº¥n luyá»‡n mÃ´ hÃ¬nh:

```bash
python train.py
```

> MÃ´ hÃ¬nh sáº½ Ä‘Æ°á»£c lÆ°u táº¡i `transformer_model.keras`.

### Trá»±c quan hÃ³a káº¿t quáº£ huáº¥n luyá»‡n:

```bash
python visualize.py
```

### ÄÃ¡nh giÃ¡ mÃ´ hÃ¬nh trÃªn táº­p kiá»ƒm tra:

```bash
python evaluate.py
```

### Cháº¡y á»©ng dá»¥ng web Streamlit:

```bash
streamlit run app.py
```

Sau Ä‘Ã³ má»Ÿ trÃ¬nh duyá»‡t táº¡i Ä‘á»‹a chá»‰: [http://localhost:8501](http://localhost:8501)

* Nháº­p Ä‘oáº¡n vÄƒn báº£n cáº§n kiá»ƒm tra
* Nháº¥n â€œğŸ” Kiá»ƒm Traâ€ Ä‘á»ƒ nháº­n káº¿t quáº£:

  * **Do AI táº¡o**
  * **Do con ngÆ°á»i viáº¿t**
    kÃ¨m theo xÃ¡c suáº¥t dá»± Ä‘oÃ¡n.

---

## ğŸ“Š Káº¿t Quáº£ Huáº¥n Luyá»‡n

* **Accuracy**: 0.9992
* **Precision**: 0.9993
* **Recall**: 0.9987
* **F1-Score**: 0.9990
* **Thá»i gian huáº¥n luyá»‡n**: 584 \~ 623 giÃ¢y (10 epoch, GPU T4)
* **á»¨ng dá»¥ng Streamlit** pháº£n há»“i nhanh (dÆ°á»›i 2 giÃ¢y).

---

## ğŸ”§ HÆ°á»›ng Cáº£i Tiáº¿n Trong TÆ°Æ¡ng Lai

* Triá»ƒn khai á»©ng dá»¥ng trÃªn **Streamlit Community Cloud** Ä‘á»ƒ truy cáº­p trá»±c tuyáº¿n.
* Tá»‘i Æ°u hÃ³a mÃ´ hÃ¬nh (tÄƒng `learning rate`, Ã¡p dá»¥ng `Early Stopping`) nháº±m giáº£m `val_loss` (hiá»‡n Ä‘áº¡t 0.6047).
* Bá»• sung tÃ­nh nÄƒng:

  * PhÃ¢n tÃ­ch tá»« khÃ³a
  * Há»— trá»£ phÃ¢n loáº¡i Ä‘a ngÃ´n ngá»¯

---

## ğŸ¤ ÄÃ³ng GÃ³p

1. Fork kho lÆ°u trá»¯.
2. Táº¡o branch má»›i:

```bash
git checkout -b feature/<tÃªn-tÃ­nh-nÄƒng>
```

3. Thá»±c hiá»‡n chá»‰nh sá»­a, commit vÃ  push:

```bash
git add .
git commit -m "ThÃªm <mÃ´ táº£ thay Ä‘á»•i>"
git push origin feature/<tÃªn-tÃ­nh-nÄƒng>
```

4. Táº¡o Pull Request Ä‘á»ƒ nhÃ³m phÃ¡t triá»ƒn xem xÃ©t.

---

## ğŸ“š TÃ i Liá»‡u Tham Kháº£o

* \[1] Chollet, F. (2018). *Deep Learning with Python.*
* \[2] Vaswani, A., et al. (2017). *Attention is All You Need.* arXiv:1706.03762.
* \[3] Goodfellow, I., et al. (2016). *Deep Learning.*
* \[4] Smith, L. N. (2018). *A disciplined approach to neural network hyper-parameters.* arXiv:1803.09820.
* \[5] Pedregosa, F., et al. (2011). *Scikit-learn: Machine Learning in Python.* JMLR.

---

## ğŸ“„ Giáº¥y PhÃ©p

Dá»± Ã¡n nÃ y Ä‘Æ°á»£c cáº¥p phÃ©p theo giáº¥y phÃ©p **MIT License**.

---

> *Cáº­p nháº­t láº§n cuá»‘i: 11:15 PM +07, Thá»© Ba, 17/06/2025*

---

---

ğŸ‘‰ **Náº¿u báº¡n muá»‘n, tÃ´i cÃ³ thá»ƒ táº¡o cho báº¡n luÃ´n file `README.md` hoÃ n chá»‰nh (chuáº©n Markdown) Ä‘á»ƒ báº¡n chá»‰ cáº§n copy-paste hoáº·c import trá»±c tiáº¿p vÃ o repo cá»§a báº¡n. Báº¡n cÃ³ muá»‘n tÃ´i táº¡o luÃ´n khÃ´ng?**
